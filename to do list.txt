New to do list:

    Organisation:
        -clean up library
        -implement .train() method and reward logger for all algorithms
        -reformat code with linting (flake/pep8)
        -standardise formatting in utils/model.py
        -standardise replaybuffer usage
        -standardise argument names

    Technical:
        -implement IQL and VDN
        -implement qr-ddpg and benchmark it vs regular ddpg

Thesis:
    -Change training loop to work with trainsteps, not episodes
    -figure out IQL improvements like VDN
    ENGINEERING:
        -experiment with converging on other coop environments
        -create trainer and config files    <- next up
        -create reward tracer with logging etc. X
        -add policy smoothing noise to MATD3

    RESEARCH:
        -look into papers re: transfer learning in MADRL
        -read into paper ivana sent and try integrate it into replay_buffer?
        -consider using different algorithms

    ENVIRONMENT:
        -look into tweaking the simple spread env to reward getting to a landmark
