ENGINEERING:
    -experiment with converging on other coop environments
    -create trainer and config files    <- next up
    -create reward tracer with logging etc. X
    -add policy smoothing noise to MATD3
    -move everything to main.py

RESEARCH:
    -look into papers re: transfer learning in MADRL
    -read into paper ivana sent and try integrate it into replay_buffer?
    -consider using different algorithms

ENVIRONMENT:
    -look into tweaking the simple spread env to reward getting to a landmark